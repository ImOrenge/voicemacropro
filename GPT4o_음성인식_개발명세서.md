# VoiceMacro Pro GPT-4o ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œ ê°œë°œëª…ì„¸ì„œ

## ğŸ“‹ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë°˜ ê°œë°œ ê°€ì´ë“œ

### ğŸ¯ Role-based Prompting (ì—­í•  ê¸°ë°˜ ì ‘ê·¼ë²•)

ë‹¹ì‹ ì€ **VoiceMacro Proì˜ ì‹œë‹ˆì–´ ìŒì„±ì¸ì‹ ê°œë°œì**ì…ë‹ˆë‹¤. ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤:

```
ì—­í•  ì •ì˜:
- OpenAI GPT-4o ì‹¤ì‹œê°„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì „ë¬¸ê°€
- Python ë°±ì—”ë“œ ë° C# WPF í”„ë¡ íŠ¸ì—”ë“œ ì•„í‚¤í…íŠ¸  
- ê²Œì„ ë§¤í¬ë¡œ ìŒì„± ëª…ë ¹ ìµœì í™” ì—”ì§€ë‹ˆì–´
- ì‹¤ì‹œê°„ WebSocket í†µì‹  ì„¤ê³„ì
```

### ğŸ”„ Chain of Thought (ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •)

#### 1ë‹¨ê³„: í˜„ì¬ ìƒí™© ë¶„ì„
```markdown
ê¸°ì¡´ ì‹œìŠ¤í…œ: Whisper ê¸°ë°˜ ìŒì„±ì¸ì‹ â†’ í•œê³„ì  ì¡´ì¬
â”œâ”€â”€ ì§€ì—°ì‹œê°„: ìŒì„± íŒŒì¼ ì—…ë¡œë“œ í›„ ì²˜ë¦¬ (3-5ì´ˆ)
â”œâ”€â”€ ì •í™•ë„: ê²Œì„ ì „ë¬¸ ìš©ì–´ ì¸ì‹ í•œê³„
â””â”€â”€ ì‹¤ì‹œê°„ì„±: ë°°ì¹˜ ì²˜ë¦¬ ë°©ì‹ì˜ í•œê³„

ëª©í‘œ ì‹œìŠ¤í…œ: GPT-4o ì‹¤ì‹œê°„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜
â”œâ”€â”€ ì§€ì—°ì‹œê°„: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (100ms ë¯¸ë§Œ)
â”œâ”€â”€ ì •í™•ë„: ê²Œì„ ëª…ë ¹ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì ìš©
â””â”€â”€ ì‹¤ì‹œê°„ì„±: WebSocket ê¸°ë°˜ ì—°ì† ì²˜ë¦¬
```

#### 2ë‹¨ê³„: ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ ë„ì¶œ
```python
# ê¸°ìˆ  ìŠ¤íƒ ê²°ì • ê³¼ì •
if ì‹¤ì‹œê°„_ì²˜ë¦¬_í•„ìš”:
    transcription_method = "GPT-4o-transcribe"  # WebSocket ê¸°ë°˜
    audio_format = "pcm16"  # 24kHz ìƒ˜í”Œë§
    buffer_size = 100  # ms ë‹¨ìœ„
else:
    transcription_method = "Whisper"  # ê¸°ì¡´ ë°©ì‹ ìœ ì§€
```

#### 3ë‹¨ê³„: ì•„í‚¤í…ì²˜ ì„¤ê³„ ê²°ì •
```mermaid
ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ í”Œë¡œìš°:
ë§ˆì´í¬ ì…ë ¥ â†’ ì˜¤ë””ì˜¤ ë²„í¼ë§ â†’ Base64 ì¸ì½”ë”© â†’ WebSocket ì „ì†¡ 
â†’ GPT-4o ì²˜ë¦¬ â†’ í…ìŠ¤íŠ¸ ë°˜í™˜ â†’ ë§¤í¬ë¡œ ë§¤ì¹­ â†’ í‚¤ë³´ë“œ ì‹¤í–‰
```

### ğŸ“š Few-shot Learning (ì˜ˆì‹œ ê¸°ë°˜ í•™ìŠµ)

#### ì˜ˆì‹œ 1: ìŒì„± ëª…ë ¹ì–´ ì²˜ë¦¬ íŒ¨í„´
```python
# ì…ë ¥ ìŒì„±: "ê³µê²© ìŠ¤í‚¬ ì‚¬ìš©í•´"
# GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼: "ê³µê²© ìŠ¤í‚¬ ì‚¬ìš©í•´"
# ì‹ ë¢°ë„: 0.95
# ë§¤ì¹­ëœ ë§¤í¬ë¡œ: attack_skill_combo
# ì‹¤í–‰ ê²°ê³¼: Qí‚¤ â†’ 0.1ì´ˆ ëŒ€ê¸° â†’ Wí‚¤ â†’ Eí‚¤

voice_command_examples = {
    "ê²Œì„ ê³µê²©": {
        "input_audio": "ê³µê²©í•´, ì–´íƒ, ë•Œë ¤",
        "transcription": "ê³µê²©í•´",
        "confidence": 0.92,
        "matched_macro": "basic_attack",
        "key_sequence": "Space"
    },
    "ìŠ¤í‚¬ ì½¤ë³´": {
        "input_audio": "ìŠ¤í‚¬ ì½¤ë³´ ì¨, ê¶ê·¹ê¸° ë°œë™",
        "transcription": "ìŠ¤í‚¬ ì½¤ë³´ ì¨",
        "confidence": 0.88,
        "matched_macro": "skill_combo",
        "key_sequence": "Q,W,E,R"
    },
    "ì´ë™ ëª…ë ¹": {
        "input_audio": "ì•ìœ¼ë¡œ ê°€, ë’¤ë¡œ ë¬¼ëŸ¬ì„œ",
        "transcription": "ì•ìœ¼ë¡œ ê°€",
        "confidence": 0.91,
        "matched_macro": "move_forward",
        "key_sequence": "W[1000]"
    }
}
```

#### ì˜ˆì‹œ 2: ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´
```python
error_handling_examples = {
    "ë‚®ì€ ì‹ ë¢°ë„": {
        "confidence": 0.65,
        "action": "ì¬ì‹œë„ ìš”ì²­",
        "message": "ìŒì„±ì„ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”"
    },
    "ì—°ê²° ì‹¤íŒ¨": {
        "error": "WebSocket connection failed",
        "fallback": "Whisper ëª¨ë¸ë¡œ ì „í™˜",
        "retry_count": 3
    },
    "API í•œë„ ì´ˆê³¼": {
        "error": "Rate limit exceeded", 
        "action": "ëŒ€ê¸° í›„ ì¬ì‹œë„",
        "wait_time": "60ì´ˆ"
    }
}
```

### ğŸ”§ Task Decomposition (ì‘ì—… ë¶„í•´)

#### ì£¼ìš” ì‘ì—… 1: Python ë°±ì—”ë“œ êµ¬í˜„
```python
class GPT4oImplementationTasks:
    """GPT-4o êµ¬í˜„ì„ ìœ„í•œ ì„¸ë¶€ ì‘ì—… ë¶„í•´"""
    
    def task_1_create_transcription_service(self):
        """
        ì‘ì—… 1: GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ìƒì„±
        â””â”€â”€ 1.1: WebSocket ì—°ê²° ê´€ë¦¬ì êµ¬í˜„
        â””â”€â”€ 1.2: ì˜¤ë””ì˜¤ ë°ì´í„° ì¸ì½”ë”©/ë””ì½”ë”©
        â””â”€â”€ 1.3: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ êµ¬í˜„
        â””â”€â”€ 1.4: ì‹ ë¢°ë„ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
        """
        subtasks = [
            "WebSocket ì—°ê²° ë° ì¸ì¦ ì²˜ë¦¬",
            "PCM16 ì˜¤ë””ì˜¤ ë°ì´í„° Base64 ì¸ì½”ë”©",
            "delta/completed ì´ë²¤íŠ¸ ë¶„ë¦¬ ì²˜ë¦¬", 
            "logprobs ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°"
        ]
        return subtasks
    
    def task_2_integrate_voice_service(self):
        """
        ì‘ì—… 2: ê¸°ì¡´ ìŒì„± ì„œë¹„ìŠ¤ í†µí•©
        â””â”€â”€ 2.1: voice_service.py ë¦¬íŒ©í† ë§
        â””â”€â”€ 2.2: ë§¤í¬ë¡œ ë§¤ì¹­ ì„œë¹„ìŠ¤ ì—°ë™
        â””â”€â”€ 2.3: ì—ëŸ¬ í•¸ë“¤ë§ ë° í´ë°± êµ¬í˜„
        â””â”€â”€ 2.4: ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì¶”ê°€
        """
        pass
    
    def task_3_websocket_api_development(self):
        """
        ì‘ì—… 3: WebSocket API ê°œë°œ
        â””â”€â”€ 3.1: Flask-SocketIO ì„œë²„ ì„¤ì •
        â””â”€â”€ 3.2: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸
        â””â”€â”€ 3.3: íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ë¸Œë¡œë“œìºìŠ¤íŒ…
        â””â”€â”€ 3.4: ì—°ê²° ìƒíƒœ ê´€ë¦¬ ë° ì¬ì—°ê²° ë¡œì§
        """
        pass
```

#### ì£¼ìš” ì‘ì—… 2: C# WPF í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„
```csharp
public class CSharpImplementationTasks
{
    /*
    ì‘ì—… 4: C# ìŒì„± ì¸ì‹ ë˜í¼ ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
    â””â”€â”€ 4.1: SocketIOClient í†µí•©
    â””â”€â”€ 4.2: NAudio ê¸°ë°˜ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìº¡ì²˜
    â””â”€â”€ 4.3: ë¹„ë™ê¸° ì´ë²¤íŠ¸ í•¸ë“¤ë§ êµ¬í˜„
    â””â”€â”€ 4.4: UI ìƒíƒœ ê´€ë¦¬ ë° ì‚¬ìš©ì í”¼ë“œë°±
    
    ì‘ì—… 5: UI ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸
    â””â”€â”€ 5.1: ì‹¤ì‹œê°„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ í‘œì‹œ
    â””â”€â”€ 5.2: ì‹ ë¢°ë„ ë° ì—°ê²° ìƒíƒœ ì¸ë””ì¼€ì´í„°
    â””â”€â”€ 5.3: ìŒì„± ì…ë ¥ ë ˆë²¨ ì‹œê°í™”
    â””â”€â”€ 5.4: ì—ëŸ¬ ë©”ì‹œì§€ ë° ì¬ì‹œë„ UI
    */
}
```

### âš™ï¸ Constraint-based Prompting (ì œì•½ ì¡°ê±´ ëª…ì‹œ)

#### ê¸°ìˆ ì  ì œì•½ì‚¬í•­
```yaml
# í•„ìˆ˜ ì¤€ìˆ˜ì‚¬í•­
constraints:
  performance:
    - ìŒì„± ì¸ì‹ ì§€ì—°ì‹œê°„: 100ms ì´í•˜
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 512MB ì´í•˜  
    - CPU ì‚¬ìš©ë¥ : 30% ì´í•˜
    
  compatibility:
    - Python 3.8+ í˜¸í™˜ì„± ìœ ì§€
    - .NET Framework 4.8+ ì§€ì›
    - Windows 10/11 í™˜ê²½ ìµœì í™”
    
  security:
    - OpenAI API í‚¤ í™˜ê²½ë³€ìˆ˜ ì €ì¥ í•„ìˆ˜
    - ìŒì„± ë°ì´í„° ë¡œì»¬ ì•”í˜¸í™”
    - HTTPS/WSS ì—°ê²°ë§Œ í—ˆìš©
    
  reliability:
    - 99.5% ì´ìƒ ê°€ë™ë¥  ëª©í‘œ
    - ìë™ ì¬ì—°ê²° ë° í´ë°± ë©”ì»¤ë‹ˆì¦˜
    - ì‹¤ì‹œê°„ í—¬ìŠ¤ì²´í¬ êµ¬í˜„
```

#### ê°œë°œ ì œì•½ì‚¬í•­
```python
# ì½”ë”© í‘œì¤€ ë° ê·œì¹™
DEVELOPMENT_CONSTRAINTS = {
    "ì½”ë“œ í’ˆì§ˆ": {
        "í•¨ìˆ˜ë³„ ì£¼ì„": "ëª¨ë“  public í•¨ìˆ˜ì— docstring í•„ìˆ˜",
        "íƒ€ì… íŒíŒ…": "Python 3.8+ typing ëª¨ë“ˆ ì‚¬ìš©",
        "ì—ëŸ¬ ì²˜ë¦¬": "ëª¨ë“  ì™¸ë¶€ API í˜¸ì¶œì— try-catch ì ìš©",
        "ë¡œê¹…": "DEBUG/INFO/WARNING/ERROR ë ˆë²¨ êµ¬ë¶„"
    },
    "ì„±ëŠ¥ ìµœì í™”": {
        "ë¹„ë™ê¸° ì²˜ë¦¬": "I/O ì‘ì—…ì€ async/await íŒ¨í„´ ì‚¬ìš©",
        "ë©”ëª¨ë¦¬ ê´€ë¦¬": "í° ê°ì²´ëŠ” ëª…ì‹œì  í•´ì œ",
        "ìºì‹±": "ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ë©”ëª¨ë¦¬ ìºì‹±"
    },
    "í…ŒìŠ¤íŠ¸": {
        "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸": "80% ì´ìƒ ì½”ë“œ ì»¤ë²„ë¦¬ì§€",
        "í†µí•© í…ŒìŠ¤íŠ¸": "ì‹¤ì œ ìŒì„± ë°ì´í„°ë¡œ E2E í…ŒìŠ¤íŠ¸",
        "ì„±ëŠ¥ í…ŒìŠ¤íŠ¸": "ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë° ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì‚¬"
    }
}
```

### ğŸ“‹ Template-based Prompting (í…œí”Œë¦¿ ê¸°ë°˜ êµ¬í˜„)

#### í…œí”Œë¦¿ 1: GPT-4o ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ êµ¬ì¡°
```python
# í…œí”Œë¦¿: backend/services/gpt4o_transcription_service.py
class GPT4oTranscriptionService:
    """
    GPT-4o ì‹¤ì‹œê°„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ í…œí”Œë¦¿
    
    Template Parameters:
    - api_key: OpenAI API í‚¤
    - language: íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì–¸ì–´ (ê¸°ë³¸ê°’: 'ko')
    - model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: 'gpt-4o-transcribe')
    """
    
    def __init__(self, api_key: str, language: str = "ko"):
        """ì´ˆê¸°í™” í…œí”Œë¦¿"""
        self.api_key = api_key
        self.language = language
        self.session_config = self._create_session_config()
        
    def _create_session_config(self) -> dict:
        """ì„¸ì…˜ ì„¤ì • í…œí”Œë¦¿ - ê²Œì„ ëª…ë ¹ì–´ ìµœì í™”"""
        return {
            "type": "transcription_session.update",
            "input_audio_format": "pcm16",
            "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "prompt": self._get_gaming_prompt(),  # ê²Œì„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
                "language": self.language
            },
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,  # ìŒì„± ê°ì§€ ì„ê³„ê°’
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500
            },
            "input_audio_noise_reduction": {
                "type": "near_field"  # ê²Œì„ìš© í—¤ë“œì…‹ ìµœì í™”
            },
            "include": ["item.input_audio_transcription.logprobs"]
        }
    
    def _get_gaming_prompt(self) -> str:
        """ê²Œì„ ëª…ë ¹ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        return """
        ê²Œì„ ìŒì„± ëª…ë ¹ì–´ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•´ì£¼ì„¸ìš”. 
        ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ì„ ìš°ì„ ì ìœ¼ë¡œ ì¸ì‹í•©ë‹ˆë‹¤:
        - ê³µê²© ê´€ë ¨: ê³µê²©, ì–´íƒ, ë•Œë ¤, ì¹˜ê¸°
        - ìŠ¤í‚¬ ê´€ë ¨: ìŠ¤í‚¬, ê¸°ìˆ , ë§ˆë²•, ê¶ê·¹ê¸°
        - ì´ë™ ê´€ë ¨: ì•ìœ¼ë¡œ, ë’¤ë¡œ, ì¢Œì¸¡, ìš°ì¸¡, ì í”„
        - ì•„ì´í…œ ê´€ë ¨: í¬ì…˜, íšŒë³µ, ì•„ì´í…œ, ì‚¬ìš©
        ê²Œì„ ì „ë¬¸ ìš©ì–´ì™€ ì§§ì€ ëª…ë ¹ì–´ë¥¼ ì •í™•íˆ ì¸ì‹í•´ì£¼ì„¸ìš”.
        """
```

#### í…œí”Œë¦¿ 2: C# ì´ë²¤íŠ¸ í•¸ë“¤ë§ êµ¬ì¡°
```csharp
// í…œí”Œë¦¿: VoiceMacroPro/Services/VoiceRecognitionWrapperService.cs
public class VoiceRecognitionWrapperService : IDisposable
{
    // Template Fields
    private SocketIOClient.SocketIO _socket;
    private WaveInEvent _waveIn;
    private readonly string _serverUrl;
    
    // Template Events
    public event EventHandler<TranscriptionResult> TranscriptionReceived;
    public event EventHandler<VoiceError> ErrorOccurred;
    public event EventHandler<ConnectionStatus> ConnectionChanged;
    
    // Template Constructor
    public VoiceRecognitionWrapperService(string serverUrl = "http://localhost:5000")
    {
        _serverUrl = serverUrl;
        InitializeComponents();
    }
    
    // Template Method: ì—°ê²° ì´ˆê¸°í™”
    public async Task<bool> InitializeAsync()
    {
        try
        {
            await ConnectToServer();
            SetupEventHandlers();
            InitializeAudioCapture();
            return true;
        }
        catch (Exception ex)
        {
            HandleInitializationError(ex);
            return false;
        }
    }
    
    // Template Method: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬
    private async void OnAudioDataAvailable(object sender, WaveInEventArgs e)
    {
        if (_isRecording && _socket.Connected)
        {
            var audioData = ProcessAudioBuffer(e.Buffer, e.BytesRecorded);
            await SendAudioToServer(audioData);
        }
    }
}
```

### ğŸ§ª Implementation Verification (êµ¬í˜„ ê²€ì¦ í…œí”Œë¦¿)

#### ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸
```markdown
## êµ¬í˜„ ì™„ë£Œ ê²€ì¦ í•­ëª©

### Phase 1: ë°±ì—”ë“œ êµ¬í˜„ ê²€ì¦
- [ ] GPT4oTranscriptionService í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ
- [ ] WebSocket ì—°ê²° ë° ì¸ì¦ ì •ìƒ ë™ì‘
- [ ] ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í™•ì¸
- [ ] íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì½œë°± ì •ìƒ ë™ì‘
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì—°ê²° ë¡œì§ í…ŒìŠ¤íŠ¸

### Phase 2: í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ ê²€ì¦  
- [ ] VoiceRecognitionWrapperService ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] SocketIOClient í†µí•© ë° í†µì‹  í™•ì¸
- [ ] NAudio ì‹¤ì‹œê°„ ë…¹ìŒ ê¸°ëŠ¥ ë™ì‘
- [ ] UI ì´ë²¤íŠ¸ ì²˜ë¦¬ ë° ìƒíƒœ í‘œì‹œ í™•ì¸
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ë° ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ

### Phase 3: í†µí•© í…ŒìŠ¤íŠ¸ ê²€ì¦
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ E2E í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë‹¤ì–‘í•œ ìŒì„± ëª…ë ¹ì–´ ì¸ì‹ ì •í™•ë„ í™•ì¸
- [ ] ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (100ms ì´í•˜ ì§€ì—°)
- [ ] ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (ì¥ì‹œê°„ ì—°ì† ì‚¬ìš©)
- [ ] ë³´ì•ˆ ê²€ì¦ (API í‚¤ ì•ˆì „í•œ ì €ì¥)
```

### ğŸš€ Deployment Strategy (ë°°í¬ ì „ëµ í…œí”Œë¦¿)

```python
# ë°°í¬ ë‹¨ê³„ë³„ ì „ëµ
deployment_phases = {
    "Phase 1 - ê°œë°œ í™˜ê²½": {
        "ëª©í‘œ": "GPT-4o ê¸°ë³¸ ê¸°ëŠ¥ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸",
        "ê¸°ê°„": "1ì£¼",
        "ì„±ê³µ ê¸°ì¤€": [
            "GPT-4o API ì—°ê²° ì„±ê³µ",
            "ê¸°ë³¸ ìŒì„± ì¸ì‹ ë™ì‘ í™•ì¸",
            "ê°„ë‹¨í•œ ë§¤í¬ë¡œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"
        ]
    },
    "Phase 2 - ìŠ¤í…Œì´ì§• í™˜ê²½": {
        "ëª©í‘œ": "ì„±ëŠ¥ ìµœì í™” ë° ì•ˆì •ì„± í™•ë³´", 
        "ê¸°ê°„": "1ì£¼",
        "ì„±ê³µ ê¸°ì¤€": [
            "ì§€ì—°ì‹œê°„ 100ms ì´í•˜ ë‹¬ì„±",
            "24ì‹œê°„ ì—°ì† ë™ì‘ ì•ˆì •ì„±",
            "ë‹¤ì–‘í•œ ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"
        ]
    },
    "Phase 3 - í”„ë¡œë•ì…˜ ë°°í¬": {
        "ëª©í‘œ": "ì‚¬ìš©ì ëŒ€ìƒ ì ì§„ì  ë°°í¬",
        "ê¸°ê°„": "1ì£¼", 
        "ì„±ê³µ ê¸°ì¤€": [
            "99.5% ê°€ë™ë¥  ë‹¬ì„±",
            "ì‚¬ìš©ì ë§Œì¡±ë„ 90% ì´ìƒ",
            "ê¸°ì¡´ Whisper ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ"
        ]
    }
}
```

## ğŸ“– êµ¬ì²´ì  êµ¬í˜„ ê°€ì´ë“œ

### 1. Python ë°±ì—”ë“œ êµ¬í˜„

#### 1.1 GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ìƒì„±
```python
# backend/services/gpt4o_transcription_service.py
import asyncio
import websockets
import json
import base64
import logging
from typing import Optional, Callable, Dict, Any
from datetime import datetime

class GPT4oTranscriptionService:
    """ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ì„ ìœ„í•œ GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: str):
        """
        GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            api_key (str): OpenAI API í‚¤
        """
        self.api_key = api_key
        self.websocket: Optional[websockets.WebSocketServerProtocol] = None
        self.session_id: Optional[str] = None
        self.is_connected = False
        self.transcription_callback: Optional[Callable] = None
        self.logger = logging.getLogger(__name__)
        
        # ê²Œì„ ëª…ë ¹ì–´ ìµœì í™”ë¥¼ ìœ„í•œ ì„¸ì…˜ ì„¤ì •
        self.session_config = {
            "type": "transcription_session.update",
            "input_audio_format": "pcm16",  # 24kHz PCM16 ì˜¤ë””ì˜¤
            "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "prompt": self._get_gaming_optimized_prompt(),
                "language": "ko"  # í•œêµ­ì–´ ê²Œì„ ëª…ë ¹ì–´
            },
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500
            },
            "input_audio_noise_reduction": {
                "type": "near_field"  # í—¤ë“œì…‹ ë§ˆì´í¬ ìµœì í™”
            },
            "include": ["item.input_audio_transcription.logprobs"]
        }
    
    def _get_gaming_optimized_prompt(self) -> str:
        """ê²Œì„ ëª…ë ¹ì–´ ì¸ì‹ ìµœì í™”ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸"""
        return """
        ê²Œì„ í”Œë ˆì´ì–´ì˜ ìŒì„± ëª…ë ¹ì–´ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ì„¸ìš”.
        ì£¼ìš” ëª…ë ¹ì–´ íŒ¨í„´:
        - ê³µê²©: ê³µê²©, ì–´íƒ, ë•Œë ¤, ì¹˜ê¸°, ê³µê²©í•´
        - ìŠ¤í‚¬: ìŠ¤í‚¬, ê¸°ìˆ , ë§ˆë²•, ê¶ê·¹ê¸°, ìŠ¤í˜ì…œ
        - ì´ë™: ì•ìœ¼ë¡œ, ë’¤ë¡œ, ì¢Œì¸¡, ìš°ì¸¡, ì í”„, ë‹¬ë ¤
        - ì•„ì´í…œ: í¬ì…˜, íšŒë³µ, ì•„ì´í…œ, ì‚¬ìš©, ë¨¹ê¸°
        - ë°©ì–´: ë°©ì–´, ë§‰ê¸°, í”¼í•˜ê¸°, íšŒí”¼
        ì§§ê³  ëª…í™•í•œ ê²Œì„ ëª…ë ¹ì–´ë¥¼ ìš°ì„  ì¸ì‹í•˜ì„¸ìš”.
        """
    
    async def connect(self) -> bool:
        """OpenAI Realtime APIì— WebSocket ì—°ê²°"""
        try:
            uri = "wss://api.openai.com/v1/realtime"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "OpenAI-Beta": "realtime=v1"
            }
            
            self.websocket = await websockets.connect(uri, extra_headers=headers)
            await self._initialize_session()
            self.is_connected = True
            self.logger.info("GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ")
            return True
            
        except Exception as e:
            self.logger.error(f"GPT-4o ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    async def _initialize_session(self):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„¸ì…˜ ì´ˆê¸°í™”"""
        await self.websocket.send(json.dumps(self.session_config))
        
        # ì„¸ì…˜ ìƒì„± í™•ì¸ ëŒ€ê¸°
        response = await self.websocket.recv()
        session_data = json.loads(response)
        
        if session_data.get("type") == "transcription_session.created":
            self.session_id = session_data.get("id")
            self.logger.info(f"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„¸ì…˜ ìƒì„±ë¨: {self.session_id}")
    
    async def send_audio_chunk(self, audio_data: bytes):
        """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡"""
        if not self.is_connected or not self.websocket:
            raise ConnectionError("íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ì— ì—°ê²°ë˜ì§€ ì•ŠìŒ")
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        message = {
            "type": "input_audio_buffer.append",
            "audio": audio_base64
        }
        
        await self.websocket.send(json.dumps(message))
    
    async def listen_for_transcriptions(self):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì‹¤ì‹œê°„ ìˆ˜ì‹ """
        try:
            async for message in self.websocket:
                data = json.loads(message)
                await self._handle_transcription_event(data)
                
        except websockets.exceptions.ConnectionClosed:
            self.logger.warning("íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì—°ê²°ì´ ì¢…ë£Œë¨")
            self.is_connected = False
        except Exception as e:
            self.logger.error(f"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
    
    async def _handle_transcription_event(self, event: Dict[str, Any]):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        event_type = event.get("type")
        
        if event_type == "conversation.item.input_audio_transcription.delta":
            # ì‹¤ì‹œê°„ ë¶€ë¶„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜
            delta_text = event.get("delta", "")
            item_id = event.get("item_id")
            
            if self.transcription_callback:
                await self.transcription_callback({
                    "type": "partial",
                    "text": delta_text,
                    "item_id": item_id,
                    "timestamp": datetime.now().isoformat()
                })
        
        elif event_type == "conversation.item.input_audio_transcription.completed":
            # ì™„ë£Œëœ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼
            transcript = event.get("transcript", "")
            item_id = event.get("item_id")
            confidence_score = self._calculate_confidence(event.get("logprobs", []))
            
            if self.transcription_callback:
                await self.transcription_callback({
                    "type": "final",
                    "text": transcript,
                    "item_id": item_id,
                    "confidence": confidence_score,
                    "timestamp": datetime.now().isoformat()
                })
        
        elif event_type == "error":
            # API ì˜¤ë¥˜ ì²˜ë¦¬
            error_msg = event.get("error", {}).get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            self.logger.error(f"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ API ì˜¤ë¥˜: {error_msg}")
    
    def _calculate_confidence(self, logprobs: list) -> float:
        """ë¡œê·¸ í™•ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not logprobs:
            return 0.0
        
        # ë¡œê·¸ í™•ë¥ ì„ í™•ë¥ ë¡œ ë³€í™˜í•˜ê³  í‰ê·  ê³„ì‚°
        probs = [min(1.0, max(0.0, 2 ** logprob)) for logprob in logprobs if logprob is not None]
        return sum(probs) / len(probs) if probs else 0.0
    
    def set_transcription_callback(self, callback: Callable):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì½œë°± í•¨ìˆ˜ ì„¤ì •"""
        self.transcription_callback = callback
    
    async def disconnect(self):
        """WebSocket ì—°ê²° ì¢…ë£Œ"""
        if self.websocket and not self.websocket.closed:
            await self.websocket.close()
        self.is_connected = False
        self.session_id = None
        self.logger.info("GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ì—°ê²° í•´ì œ")
```

#### 1.2 ìŒì„± ì„œë¹„ìŠ¤ í†µí•© ì—…ë°ì´íŠ¸
```python
# backend/services/voice_service.py ì—…ë°ì´íŠ¸
import asyncio
from .gpt4o_transcription_service import GPT4oTranscriptionService
from .macro_matching_service import MacroMatchingService
from ..utils.config import get_openai_api_key

class VoiceService:
    """GPT-4o ì‹¤ì‹œê°„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ì„ ì‚¬ìš©í•˜ëŠ” ê°œì„ ëœ ìŒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ìŒì„± ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.transcription_service = GPT4oTranscriptionService(get_openai_api_key())
        self.macro_matching_service = MacroMatchingService()
        self.current_transcription = ""
        self.is_recording = False
        self.confidence_threshold = 0.7  # ì‹ ë¢°ë„ ì„ê³„ê°’
        
    async def initialize(self):
        """ìŒì„± ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì—°ê²° ì„¤ì •"""
        success = await self.transcription_service.connect()
        if success:
            self.transcription_service.set_transcription_callback(self._handle_transcription_result)
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ìˆ˜ì‹  ì‹œì‘
            asyncio.create_task(self.transcription_service.listen_for_transcriptions())
        return success
    
    async def _handle_transcription_result(self, transcription_data):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì²˜ë¦¬ ë° ë§¤í¬ë¡œ ë§¤ì¹­"""
        if transcription_data["type"] == "final":
            transcript = transcription_data["text"].strip()
            confidence = transcription_data["confidence"]
            
            self.logger.info(f"ìŒì„± ì¸ì‹ ê²°ê³¼: '{transcript}' (ì‹ ë¢°ë„: {confidence:.2f})")
            
            # ê³ ì‹ ë¢°ë„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ë§Œ ì²˜ë¦¬
            if confidence > self.confidence_threshold:
                # ë§¤í¬ë¡œ ë§¤ì¹­ ì„œë¹„ìŠ¤ì— ì „ë‹¬
                await self.macro_matching_service.process_voice_command(
                    transcript, confidence
                )
                
                # ì„±ê³µì ì¸ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ë¡œê·¸ ê¸°ë¡
                self._log_successful_transcription(transcript, confidence)
            else:
                self.logger.warning(f"ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì¸í•œ ë¬´ì‹œ: {confidence:.2f}")
    
    async def start_recording(self):
        """ìŒì„± ë…¹ìŒ ì‹œì‘"""
        self.is_recording = True
        self.logger.info("ìŒì„± ë…¹ìŒ ì‹œì‘")
        # ì‹¤ì œ ë§ˆì´í¬ ìº¡ì²˜ëŠ” C# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬
    
    async def stop_recording(self):
        """ìŒì„± ë…¹ìŒ ì¤‘ì§€"""
        self.is_recording = False
        # ë‚¨ì€ ì˜¤ë””ì˜¤ ë²„í¼ ì»¤ë°‹
        await self.transcription_service.commit_audio_buffer()
        self.logger.info("ìŒì„± ë…¹ìŒ ì¤‘ì§€")
    
    def _log_successful_transcription(self, transcript: str, confidence: float):
        """ì„±ê³µì ì¸ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ë¡œê·¸ ê¸°ë¡"""
        # ë¡œê¹… ì„œë¹„ìŠ¤ì— ê¸°ë¡ (êµ¬í˜„ í•„ìš”)
        pass
```

### 2. C# WPF í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„

#### 2.1 ìŒì„± ì¸ì‹ ë˜í¼ ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
```csharp
// VoiceMacroPro/Services/VoiceRecognitionWrapperService.cs
using System;
using System.Threading.Tasks;
using SocketIOClient;
using NAudio.Wave;
using System.IO;

public class VoiceRecognitionWrapperService : IDisposable
{
    private SocketIOClient.SocketIO _socket;
    private WaveInEvent _waveIn;
    private bool _isRecording = false;
    private readonly string _serverUrl;
    
    // ì´ë²¤íŠ¸ ì •ì˜
    public event EventHandler<TranscriptionResult> TranscriptionReceived;
    public event EventHandler<string> ErrorOccurred;
    public event EventHandler<ConnectionStatus> ConnectionChanged;
    
    public VoiceRecognitionWrapperService(string serverUrl = "http://localhost:5000")
    {
        _serverUrl = serverUrl;
    }
    
    /// <summary>
    /// ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    /// </summary>
    public async Task<bool> InitializeAsync()
    {
        try
        {
            // Python ë°±ì—”ë“œ WebSocket ì—°ê²°
            _socket = new SocketIOClient.SocketIO(_serverUrl);
            
            // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
            _socket.On("transcription_result", HandleTranscriptionResult);
            _socket.On("voice_recognition_error", HandleError);
            _socket.On("connection_status", HandleConnectionStatus);
            
            await _socket.ConnectAsync();
            
            // ì˜¤ë””ì˜¤ ìº¡ì²˜ ì´ˆê¸°í™”
            InitializeAudioCapture();
            
            ConnectionChanged?.Invoke(this, new ConnectionStatus { IsConnected = true });
            return true;
        }
        catch (Exception ex)
        {
            ErrorOccurred?.Invoke(this, $"ì´ˆê¸°í™” ì‹¤íŒ¨: {ex.Message}");
            return false;
        }
    }
    
    /// <summary>
    /// ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„¤ì •
    /// </summary>
    private void InitializeAudioCapture()
    {
        _waveIn = new WaveInEvent();
        // GPT-4oì— ìµœì í™”ëœ ì˜¤ë””ì˜¤ ì„¤ì •: 24kHz, 16-bit, ëª¨ë…¸
        _waveIn.WaveFormat = new WaveFormat(24000, 16, 1);
        _waveIn.BufferMilliseconds = 100; // 100ms ë²„í¼ë¡œ ì‹¤ì‹œê°„ ì²˜ë¦¬
        
        _waveIn.DataAvailable += OnAudioDataAvailable;
        _waveIn.RecordingStopped += OnRecordingStopped;
    }
    
    /// <summary>
    /// ì˜¤ë””ì˜¤ ë°ì´í„° ì‹¤ì‹œê°„ ì²˜ë¦¬ ë° ì „ì†¡
    /// </summary>
    private async void OnAudioDataAvailable(object sender, WaveInEventArgs e)
    {
        if (_isRecording && _socket.Connected)
        {
            try
            {
                // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ì†¡
                string audioBase64 = Convert.ToBase64String(e.Buffer, 0, e.BytesRecorded);
                
                await _socket.EmitAsync("audio_chunk", new { audio = audioBase64 });
            }
            catch (Exception ex)
            {
                ErrorOccurred?.Invoke(this, $"ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: {ex.Message}");
            }
        }
    }
    
    /// <summary>
    /// ìŒì„± ë…¹ìŒ ì‹œì‘
    /// </summary>
    public async Task StartRecordingAsync()
    {
        if (!_isRecording)
        {
            _isRecording = true;
            _waveIn.StartRecording();
            await _socket.EmitAsync("start_voice_recognition");
        }
    }
    
    /// <summary>
    /// ìŒì„± ë…¹ìŒ ì¤‘ì§€
    /// </summary>
    public async Task StopRecordingAsync()
    {
        if (_isRecording)
        {
            _isRecording = false;
            _waveIn.StopRecording();
            await _socket.EmitAsync("stop_voice_recognition");
        }
    }
    
    /// <summary>
    /// íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì²˜ë¦¬
    /// </summary>
    private void HandleTranscriptionResult(SocketIOResponse response)
    {
        try
        {
            var data = response.GetValue<TranscriptionData>();
            
            var result = new TranscriptionResult
            {
                Type = data.type,
                Text = data.text,
                Confidence = data.confidence,
                Timestamp = DateTime.Parse(data.timestamp)
            };
            
            TranscriptionReceived?.Invoke(this, result);
        }
        catch (Exception ex)
        {
            ErrorOccurred?.Invoke(this, $"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {ex.Message}");
        }
    }
    
    /// <summary>
    /// ì˜¤ë¥˜ ì²˜ë¦¬
    /// </summary>
    private void HandleError(SocketIOResponse response)
    {
        var error = response.GetValue<ErrorData>();
        ErrorOccurred?.Invoke(this, error.error);
    }
    
    /// <summary>
    /// ì—°ê²° ìƒíƒœ ë³€ê²½ ì²˜ë¦¬
    /// </summary>
    private void HandleConnectionStatus(SocketIOResponse response)
    {
        var status = response.GetValue<ConnectionStatus>();
        ConnectionChanged?.Invoke(this, status);
    }
    
    /// <summary>
    /// ë…¹ìŒ ì¤‘ì§€ ì´ë²¤íŠ¸ ì²˜ë¦¬
    /// </summary>
    private void OnRecordingStopped(object sender, StoppedEventArgs e)
    {
        if (e.Exception != null)
        {
            ErrorOccurred?.Invoke(this, $"ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜: {e.Exception.Message}");
        }
    }
    
    /// <summary>
    /// ë¦¬ì†ŒìŠ¤ í•´ì œ
    /// </summary>
    public void Dispose()
    {
        _waveIn?.Dispose();
        _socket?.DisconnectAsync();
    }
}

// ë°ì´í„° ì „ì†¡ ê°ì²´ë“¤
public class TranscriptionResult
{
    public string Type { get; set; }
    public string Text { get; set; }
    public double Confidence { get; set; }
    public DateTime Timestamp { get; set; }
}

public class TranscriptionData
{
    public string type { get; set; }
    public string text { get; set; }
    public double confidence { get; set; }
    public string timestamp { get; set; }
}

public class ErrorData
{
    public string error { get; set; }
}

public class ConnectionStatus
{
    public bool IsConnected { get; set; }
    public string Status { get; set; }
}
```

### 3. ì„¤ì • ë° ì¢…ì†ì„± ê´€ë¦¬

#### 3.1 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```python
# backend/utils/config.py ì—…ë°ì´íŠ¸
import os
from typing import Dict, Any

def get_openai_api_key() -> str:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    return api_key

def get_transcription_config() -> Dict[str, Any]:
    """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„¤ì • ë°˜í™˜"""
    return {
        'model': 'gpt-4o-transcribe',
        'language': 'ko',  # í•œêµ­ì–´ VoiceMacro Proìš©
        'noise_reduction': 'near_field',
        'vad_threshold': 0.5,
        'confidence_threshold': 0.7,
        'buffer_size_ms': 100,
        'sample_rate': 24000
    }

def get_websocket_config() -> Dict[str, Any]:
    """WebSocket ì„¤ì • ë°˜í™˜"""
    return {
        'host': 'localhost',
        'port': 5000,
        'cors_allowed_origins': "*",
        'reconnect_attempts': 3,
        'reconnect_delay': 5
    }
```

#### 3.2 ì¢…ì†ì„± ì—…ë°ì´íŠ¸
```txt
# requirements.txt ì—…ë°ì´íŠ¸
websockets>=11.0.0
openai>=1.3.0
flask>=2.3.0
flask-socketio>=5.3.0
asyncio>=3.4.3
numpy>=1.24.0
logging>=0.4.9.6
```

```xml
<!-- VoiceMacroPro/VoiceMacroPro.csproj ì—…ë°ì´íŠ¸ -->
<Project Sdk="Microsoft.NET.Sdk">
  <PropertyGroup>
    <OutputType>WinExe</OutputType>
    <TargetFramework>net6.0-windows</TargetFramework>
    <UseWPF>true</UseWPF>
  </PropertyGroup>
  
  <ItemGroup>
    <PackageReference Include="SocketIOClient" Version="3.0.6" />
    <PackageReference Include="NAudio" Version="2.2.1" />
    <PackageReference Include="Newtonsoft.Json" Version="13.0.3" />
    <PackageReference Include="System.Threading.Tasks.Extensions" Version="4.5.4" />
  </ItemGroup>
</Project>
```

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

### ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì 
```python
# backend/utils/performance_monitor.py
import time
import psutil
import logging
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: float
    latency_ms: float
    cpu_usage: float
    memory_usage_mb: float
    transcription_accuracy: float
    connection_status: bool

class PerformanceMonitor:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.metrics_history: List[PerformanceMetrics] = []
        self.logger = logging.getLogger(__name__)
        self.start_time = time.time()
    
    def record_transcription_latency(self, start_time: float, end_time: float):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì§€ì—°ì‹œê°„ ê¸°ë¡"""
        latency_ms = (end_time - start_time) * 1000
        
        metrics = PerformanceMetrics(
            timestamp=time.time(),
            latency_ms=latency_ms,
            cpu_usage=psutil.cpu_percent(),
            memory_usage_mb=psutil.Process().memory_info().rss / 1024 / 1024,
            transcription_accuracy=0.0,  # ë³„ë„ ê³„ì‚° í•„ìš”
            connection_status=True
        )
        
        self.metrics_history.append(metrics)
        
        # ì„±ëŠ¥ ê²½ê³  ì²´í¬
        if latency_ms > 100:  # 100ms ì´ˆê³¼ì‹œ ê²½ê³ 
            self.logger.warning(f"ë†’ì€ ì§€ì—°ì‹œê°„ ê°ì§€: {latency_ms:.2f}ms")
    
    def get_average_performance(self, last_n_minutes: int = 5) -> Dict:
        """ìµœê·¼ Në¶„ê°„ í‰ê·  ì„±ëŠ¥ ë°˜í™˜"""
        cutoff_time = time.time() - (last_n_minutes * 60)
        recent_metrics = [m for m in self.metrics_history if m.timestamp > cutoff_time]
        
        if not recent_metrics:
            return {}
        
        return {
            'avg_latency_ms': sum(m.latency_ms for m in recent_metrics) / len(recent_metrics),
            'avg_cpu_usage': sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics),
            'avg_memory_mb': sum(m.memory_usage_mb for m in recent_metrics) / len(recent_metrics),
            'total_transcriptions': len(recent_metrics)
        }
```

ì´ ê°œë°œëª…ì„¸ì„œëŠ” **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ 6ê°€ì§€ í•µì‹¬ ê¸°ë²•**ì„ í™œìš©í•˜ì—¬ VoiceMacro Proì˜ GPT-4o ìŒì„±ì¸ì‹ ì‹œìŠ¤í…œ êµ¬í˜„ì„ ìœ„í•œ **ì‹¤í–‰ ê°€ëŠ¥í•œ ë¡œë“œë§µ**ì„ ì œê³µí•©ë‹ˆë‹¤. ê° ë‹¨ê³„ë³„ë¡œ êµ¬ì²´ì ì¸ êµ¬í˜„ ê°€ì´ë“œ, ì˜ˆì‹œ ì½”ë“œ, ê²€ì¦ ë°©ë²•ì„ í¬í•¨í•˜ì—¬ ê°œë°œìê°€ ë‹¨ê³„ë³„ë¡œ ë”°ë¼ê°ˆ ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 