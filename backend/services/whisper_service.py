"""
VoiceMacro Pro - OpenAI Whisper ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤
ì‹¤ì œ OpenAI Whisper APIë¥¼ ì‚¬ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ë° ë§¤í¬ë¡œ ë§¤ì¹­
"""

import os
import io
import wave
import tempfile
import numpy as np
from typing import Optional, List, Dict, Tuple
from openai import OpenAI
from difflib import SequenceMatcher
import logging
from datetime import datetime

from backend.utils.config import config
from backend.utils.common_utils import get_logger
from backend.services.macro_service import macro_service


class WhisperService:
    """
    OpenAI Whisper APIë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    - ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ OpenAI Whisper APIë¡œ ì „ì†¡
    - ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ìˆ˜í–‰
    - ë³€í™˜ëœ í…ìŠ¤íŠ¸ì™€ ë§¤í¬ë¡œ ëª…ë ¹ì–´ ë§¤ì¹­
    """
    
    def __init__(self):
        """Whisper ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.logger = get_logger(__name__)
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            if not config.OPENAI_API_KEY:
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            self.client = OpenAI(api_key=config.OPENAI_API_KEY)
            self.logger.info("OpenAI Whisper í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.client = None
        
        # ì„¤ì • ê°’ë“¤
        self.model = config.WHISPER_MODEL
        self.language = config.VOICE_RECOGNITION_LANGUAGE
        self.sample_rate = config.SAMPLE_RATE
        self.channels = config.AUDIO_CHANNELS
        
        # ë§¤í¬ë¡œ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”ìš©)
        self._macro_cache = []
        self._cache_last_updated = None
        
        self.logger.info("Whisper ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _save_audio_to_file(self, audio_data: np.ndarray) -> str:
        """
        numpy ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
        ğŸ”§ ë¹ˆ íŒŒì¼ ìƒì„± ë°©ì§€ë¥¼ ìœ„í•œ ê°•í™”ëœ ê²€ì¦ ì¶”ê°€
        
        Args:
            audio_data (np.ndarray): ì˜¤ë””ì˜¤ ë°ì´í„° ë°°ì—´
            
        Returns:
            str: ì €ì¥ëœ ì„ì‹œ íŒŒì¼ ê²½ë¡œ
            
        Raises:
            ValueError: ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
            IOError: íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í•œ ê²½ìš°
        """
        try:
            # ğŸ” ì…ë ¥ ë°ì´í„° ê²€ì¦
            if audio_data is None:
                raise ValueError("ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ Noneì…ë‹ˆë‹¤.")
            
            if not isinstance(audio_data, np.ndarray):
                raise ValueError(f"ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ numpy ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤: {type(audio_data)}")
            
            if audio_data.size == 0:
                raise ValueError("ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            # 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜ (ë‹¤ì°¨ì›ì¸ ê²½ìš° flatten)
            if audio_data.ndim > 1:
                audio_data = audio_data.flatten()
                self.logger.debug(f"ë‹¤ì°¨ì› ë°°ì—´ì„ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜: {audio_data.shape}")
            
            # ë°ì´í„° íƒ€ì… ë° ë²”ìœ„ í™•ì¸
            self.logger.debug(f"ğŸ“Š ì˜¤ë””ì˜¤ ë°ì´í„° ì •ë³´:")
            self.logger.debug(f"   - í˜•íƒœ: {audio_data.shape}")
            self.logger.debug(f"   - íƒ€ì…: {audio_data.dtype}")
            self.logger.debug(f"   - ìµœì†Œê°’: {audio_data.min():.6f}")
            self.logger.debug(f"   - ìµœëŒ€ê°’: {audio_data.max():.6f}")
            self.logger.debug(f"   - í‰ê· ê°’: {audio_data.mean():.6f}")
            self.logger.debug(f"   - í‘œì¤€í¸ì°¨: {audio_data.std():.6f}")
            
            # ğŸµ ì˜¤ë””ì˜¤ ì‹ í˜¸ í’ˆì§ˆ ê²€ì¦
            signal_energy = np.sum(audio_data ** 2)  # ì‹ í˜¸ ì—ë„ˆì§€
            signal_max_amplitude = np.max(np.abs(audio_data))  # ìµœëŒ€ ì§„í­
            
            self.logger.debug(f"ğŸ¶ ì‹ í˜¸ í’ˆì§ˆ ë¶„ì„:")
            self.logger.debug(f"   - ì‹ í˜¸ ì—ë„ˆì§€: {signal_energy:.6f}")
            self.logger.debug(f"   - ìµœëŒ€ ì§„í­: {signal_max_amplitude:.6f}")
            
            # ìµœì†Œ ì‹ í˜¸ ê°•ë„ í™•ì¸
            if signal_energy < 1e-8:  # ë§¤ìš° ì‘ì€ ê°’
                self.logger.warning(f"âš ï¸  ì‹ í˜¸ ì—ë„ˆì§€ê°€ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤: {signal_energy}")
            
            if signal_max_amplitude < 1e-6:  # ë§¤ìš° ì‘ì€ ì§„í­
                self.logger.warning(f"âš ï¸  ì‹ í˜¸ ì§„í­ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤: {signal_max_amplitude}")
            
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            temp_file = tempfile.NamedTemporaryFile(
                suffix='.wav', 
                dir=config.TEMP_AUDIO_DIR, 
                delete=False
            )
            temp_path = temp_file.name
            temp_file.close()  # íŒŒì¼ í•¸ë“¤ ë‹«ê¸° (Windows í˜¸í™˜ì„±)
            
            # ğŸ”„ ë°ì´í„° í˜•ì‹ ë³€í™˜ ë° ì •ê·œí™”
            if audio_data.dtype == np.float32 or audio_data.dtype == np.float64:
                # float íƒ€ì… (-1.0 ~ 1.0 ë²”ìœ„ë¡œ ê°€ì •)
                # ë²”ìœ„ í™•ì¸ ë° ì •ê·œí™”
                if np.max(np.abs(audio_data)) > 1.0:
                    self.logger.warning(f"âš ï¸  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ [-1,1] ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨, ì •ê·œí™” ì ìš©")
                    max_val = np.max(np.abs(audio_data))
                    audio_data = audio_data / max_val
                
                # int16ìœ¼ë¡œ ë³€í™˜ (-32768 ~ 32767)
                audio_int16 = (audio_data * 32767).astype(np.int16)
                
            elif audio_data.dtype == np.int16:
                # ì´ë¯¸ int16ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                audio_int16 = audio_data
                
            elif audio_data.dtype == np.int32:
                # int32ì—ì„œ int16ìœ¼ë¡œ ë³€í™˜
                audio_int16 = (audio_data / 65536).astype(np.int16)
                
            else:
                # ê¸°íƒ€ íƒ€ì…ì€ floatë¡œ ë³€í™˜ í›„ ì²˜ë¦¬
                audio_float = audio_data.astype(np.float32)
                max_val = np.max(np.abs(audio_float))
                if max_val > 0:
                    audio_float = audio_float / max_val
                audio_int16 = (audio_float * 32767).astype(np.int16)
                self.logger.debug(f"ğŸ”„ íƒ€ì… ë³€í™˜: {audio_data.dtype} -> int16")
            
            # ë³€í™˜ëœ ë°ì´í„° ê²€ì¦
            if audio_int16.size == 0:
                raise ValueError("ë³€í™˜ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            # ì˜ˆìƒ íŒŒì¼ í¬ê¸° ê³„ì‚° (ë°”ì´íŠ¸ ë‹¨ìœ„)
            expected_size = audio_int16.size * 2 + 44  # PCM ë°ì´í„° + WAV í—¤ë”
            expected_duration = audio_int16.size / self.sample_rate  # ì´ˆ ë‹¨ìœ„
            
            self.logger.debug(f"ğŸ’¾ ì €ì¥ ì˜ˆì • ì •ë³´:")
            self.logger.debug(f"   - ìƒ˜í”Œ ìˆ˜: {audio_int16.size}")
            self.logger.debug(f"   - ì˜ˆìƒ í¬ê¸°: {expected_size} ë°”ì´íŠ¸")
            self.logger.debug(f"   - ì˜ˆìƒ ê¸¸ì´: {expected_duration:.2f} ì´ˆ")
            
            # ğŸµ WAV íŒŒì¼ë¡œ ì €ì¥
            with wave.open(temp_path, 'wb') as wav_file:
                wav_file.setnchannels(self.channels)     # 1 (ëª¨ë…¸)
                wav_file.setsampwidth(2)                 # 16-bit = 2 bytes
                wav_file.setframerate(self.sample_rate)  # 16000 Hz
                wav_file.writeframes(audio_int16.tobytes())
            
            # ğŸ’¾ ì €ì¥ëœ íŒŒì¼ ê²€ì¦
            if not os.path.exists(temp_path):
                raise IOError(f"WAV íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {temp_path}")
            
            actual_size = os.path.getsize(temp_path)
            if actual_size == 0:
                os.remove(temp_path)  # ë¹ˆ íŒŒì¼ ì‚­ì œ
                raise IOError("ë¹ˆ WAV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            if actual_size < 100:  # ìµœì†Œ í¬ê¸° (WAV í—¤ë” + ì¼ë¶€ ë°ì´í„°)
                os.remove(temp_path)  # ë„ˆë¬´ ì‘ì€ íŒŒì¼ ì‚­ì œ
                raise IOError(f"WAV íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {actual_size} ë°”ì´íŠ¸")
            
            # ğŸ“Š ìµœì¢… ê²€ì¦ ì •ë³´ ë¡œê¹…
            size_difference = abs(actual_size - expected_size)
            self.logger.info(f"âœ… WAV íŒŒì¼ ì €ì¥ ì„±ê³µ!")
            self.logger.info(f"ğŸ“ íŒŒì¼ ê²½ë¡œ: {temp_path}")
            self.logger.info(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {actual_size} ë°”ì´íŠ¸ (ì˜ˆìƒ: {expected_size})")
            self.logger.info(f"â±ï¸  ì˜¤ë””ì˜¤ ê¸¸ì´: {expected_duration:.2f} ì´ˆ")
            
            if size_difference > 100:  # 100ë°”ì´íŠ¸ ì´ìƒ ì°¨ì´ë‚˜ë©´ ê²½ê³ 
                self.logger.warning(f"âš ï¸  ì˜ˆìƒ í¬ê¸°ì™€ ì‹¤ì œ í¬ê¸° ì°¨ì´: {size_difference} ë°”ì´íŠ¸")
            
            return temp_path
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•œ ê²½ìš° ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'temp_path' in locals() and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except:
                    pass
            raise IOError(f"ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _cleanup_temp_file(self, file_path: str):
        """
        ì„ì‹œ íŒŒì¼ ì •ë¦¬
        
        Args:
            file_path (str): ì‚­ì œí•  íŒŒì¼ ê²½ë¡œ
        """
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                self.logger.debug(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
        except Exception as e:
            self.logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    def transcribe_audio(self, audio_input) -> Dict:
        """
        ì˜¤ë””ì˜¤ ë°ì´í„° ë˜ëŠ” íŒŒì¼ì„ OpenAI Whisper APIë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        ğŸ¯ ì •í™•ë„ ê°œì„ ì„ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ìµœì í™” ì ìš©
        
        Args:
            audio_input: ì˜¤ë””ì˜¤ ë°ì´í„° (np.ndarray) ë˜ëŠ” íŒŒì¼ ê²½ë¡œ (str)
            
        Returns:
            Dict: ë³€í™˜ ê²°ê³¼ {'success': bool, 'text': str, 'confidence': float}
        """
        if self.client is None:
            self.logger.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {'success': False, 'text': '', 'confidence': 0.0, 'error': 'OpenAI í´ë¼ì´ì–¸íŠ¸ ë¯¸ì´ˆê¸°í™”'}
        
        temp_file_path = None
        file_created_by_us = False
        
        try:
            # ì…ë ¥ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
            if isinstance(audio_input, str):
                # íŒŒì¼ ê²½ë¡œê°€ ì „ë‹¬ëœ ê²½ìš°
                if not os.path.exists(audio_input):
                    self.logger.error(f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {audio_input}")
                    return {'success': False, 'text': '', 'confidence': 0.0, 'error': 'íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ'}
                
                temp_file_path = audio_input
                self.logger.debug(f"íŒŒì¼ ê²½ë¡œë¡œ ì „ë‹¬ë¨: {temp_file_path}")
                
            elif isinstance(audio_input, np.ndarray):
                # numpy ë°°ì—´ì´ ì „ë‹¬ëœ ê²½ìš°
                temp_file_path = self._save_audio_to_file(audio_input)
                file_created_by_us = True
                self.logger.debug(f"numpy ë°°ì—´ì„ íŒŒì¼ë¡œ ì €ì¥í•¨: {temp_file_path}")
                
            else:
                self.logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ ì…ë ¥ íƒ€ì…: {type(audio_input)}")
                return {'success': False, 'text': '', 'confidence': 0.0, 'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…'}
            
            # ğŸ” ì˜¤ë””ì˜¤ íŒŒì¼ í’ˆì§ˆ ê²€ì¦ (ë¹ˆ íŒŒì¼ ë°©ì§€)
            file_size_bytes = os.path.getsize(temp_file_path)
            file_size_mb = file_size_bytes / (1024 * 1024)
            
            # ìµœì†Œ íŒŒì¼ í¬ê¸° ê²€ì¦ (100ë°”ì´íŠ¸ ì´ìƒ)
            if file_size_bytes < 100:
                self.logger.error(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {file_size_bytes}ë°”ì´íŠ¸ (ë¹ˆ íŒŒì¼ë¡œ ì¶”ì •)")
                return {'success': False, 'text': '', 'confidence': 0.0, 'error': f'ì˜¤ë””ì˜¤ íŒŒì¼ ë„ˆë¬´ ì‘ìŒ: {file_size_bytes}ë°”ì´íŠ¸'}
            
            # ìµœëŒ€ íŒŒì¼ í¬ê¸° ê²€ì¦ (OpenAIëŠ” 25MB ì œí•œ)
            if file_size_mb > config.VOICE_RECOGNITION_MAX_FILE_SIZE:
                self.logger.error(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {file_size_mb:.1f}MB")
                return {'success': False, 'text': '', 'confidence': 0.0, 'error': f'íŒŒì¼ í¬ê¸° ì´ˆê³¼: {file_size_mb:.1f}MB'}
            
            # ì˜¤ë””ì˜¤ ì§€ì†ì‹œê°„ ì¶”ì • (16kHz ëª¨ë…¸ ê¸°ì¤€)
            estimated_duration = file_size_bytes / (self.sample_rate * 2)  # 16-bit = 2 bytes per sample
            
            self.logger.info(f"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì™„ë£Œ - í¬ê¸°: {file_size_bytes}ë°”ì´íŠ¸ ({file_size_mb:.2f}MB), ì˜ˆìƒ ê¸¸ì´: {estimated_duration:.1f}ì´ˆ")
            
            # ğŸ¯ ê²Œì„ ë§¤í¬ë¡œ ëª…ë ¹ì–´ ìµœì í™”ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            optimization_prompt = (
                "ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì¸ì‹í•´ì¤˜"
            )
            
            self.logger.info(f"ğŸš€ Whisper API í˜¸ì¶œ ì‹œì‘ (ìµœì í™”ëœ ì„¤ì • ì ìš©)")
            
            # ğŸ”§ OpenAI Whisper API í˜¸ì¶œ (ì •í™•ë„ ìµœì í™” ì„¤ì •)
            with open(temp_file_path, 'rb') as audio_file:
                response = self.client.audio.transcriptions.create(
                    model=self.model,              # whisper-1
                    file=audio_file,               # ì˜¤ë””ì˜¤ íŒŒì¼
                    language=self.language,        # ko (í•œêµ­ì–´)
                    response_format="verbose_json", # ìƒì„¸ ì •ë³´ í¬í•¨ (ì‹ ë¢°ë„ ë“±)
                    temperature=0.0,               # ì°½ì˜ì„± ìµœì†Œí™” (ì •í™•ë„ ìš°ì„ )
                    prompt=optimization_prompt     # ê²Œì„ ë§¤í¬ë¡œ ëª…ë ¹ì–´ íŒíŠ¸
                )
            
            # ğŸ” ìƒì„¸ ì‘ë‹µ ì •ë³´ ì¶”ì¶œ
            transcribed_text = response.text.strip() if response.text else ""
            
            # verbose_json ì‘ë‹µì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            language_detected = getattr(response, 'language', 'unknown')
            duration = getattr(response, 'duration', 0.0)
            
            # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ìˆìœ¼ë©´ í‰ê·  í™•ì‹ ë„ ê³„ì‚°
            segments = getattr(response, 'segments', [])
            if segments and len(segments) > 0:
                # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ í‰ê·  í™•ì‹ ë„ ê³„ì‚°
                confidences = []
                for segment in segments:
                    if hasattr(segment, 'avg_logprob'):
                        # log probabilityë¥¼ í™•ë¥ ë¡œ ë³€í™˜ (0.0 ~ 1.0)
                        confidence = min(1.0, max(0.0, np.exp(segment.avg_logprob)))
                        confidences.append(confidence)
                
                if confidences:
                    avg_confidence = sum(confidences) / len(confidences)
                else:
                    # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì¶”ì •
                    avg_confidence = min(0.95, 0.6 + (len(transcribed_text) * 0.03))
            else:
                # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì¶”ì •
                avg_confidence = min(0.95, 0.6 + (len(transcribed_text) * 0.03))
            
            if transcribed_text:
                self.logger.info(f"âœ… Whisper ìŒì„± ì¸ì‹ ì„±ê³µ!")
                self.logger.info(f"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{transcribed_text}'")
                self.logger.info(f"ğŸ¯ ì‹ ë¢°ë„: {avg_confidence:.2f} ({avg_confidence*100:.1f}%)")
                self.logger.info(f"ğŸŒ ê°ì§€ëœ ì–¸ì–´: {language_detected}")
                self.logger.info(f"â±ï¸  ì˜¤ë””ì˜¤ ê¸¸ì´: {duration:.1f}ì´ˆ")
                
                return {
                    'success': True,
                    'text': transcribed_text,
                    'confidence': avg_confidence,
                    'source': 'whisper',
                    'language': language_detected,
                    'duration': duration,
                    'segments_count': len(segments)
                }
            else:
                self.logger.warning("ğŸ”‡ Whisper ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                self.logger.warning(f"ğŸ” ë””ë²„ê·¸ ì •ë³´ - ì–¸ì–´: {language_detected}, ê¸¸ì´: {duration:.1f}ì´ˆ")
                return {
                    'success': False,
                    'text': '',
                    'confidence': 0.0,
                    'error': 'ì¸ì‹ ê²°ê³¼ ì—†ìŒ',
                    'language': language_detected,
                    'duration': duration
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Whisper API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ ë¡œê¹…
            if hasattr(e, 'response'):
                self.logger.error(f"ğŸ” API ì‘ë‹µ ìƒì„¸: {e.response}")
            return {
                'success': False,
                'text': '',
                'confidence': 0.0,
                'error': f'API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}'
            }
        
        finally:
            # ìš°ë¦¬ê°€ ë§Œë“  ì„ì‹œ íŒŒì¼ë§Œ ì •ë¦¬
            if temp_file_path and file_created_by_us:
                self._cleanup_temp_file(temp_file_path)
    
    def _update_macro_cache(self):
        """
        ë§¤í¬ë¡œ ìºì‹œ ì—…ë°ì´íŠ¸ (ì„±ëŠ¥ ìµœì í™”)
        """
        try:
            # 5ë¶„ë§ˆë‹¤ ìºì‹œ ê°±ì‹ 
            now = datetime.now()
            if (self._cache_last_updated is None or 
                (now - self._cache_last_updated).seconds > 300):
                
                self._macro_cache = macro_service.get_all_macros()
                self._cache_last_updated = now
                self.logger.debug(f"ë§¤í¬ë¡œ ìºì‹œ ê°±ì‹  ì™„ë£Œ: {len(self._macro_cache)}ê°œ")
                
        except Exception as e:
            self.logger.error(f"ë§¤í¬ë¡œ ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ê²Œì„ ë§¤í¬ë¡œ ëª…ë ¹ì–´ íŠ¹í™”)
        ğŸ¯ í•œêµ­ì–´ ê²Œì„ ëª…ë ¹ì–´ ì¸ì‹ ì •í™•ë„ ìµœì í™”
        
        Args:
            text1 (str): ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ (ì¸ì‹ëœ ìŒì„±)
            text2 (str): ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸ (ë“±ë¡ëœ ë§¤í¬ë¡œ ëª…ë ¹ì–´)
            
        Returns:
            float: ìœ ì‚¬ë„ (0.0 ~ 1.0)
        """
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        clean_text1 = text1.strip().lower().replace(" ", "")
        clean_text2 = text2.strip().lower().replace(" ", "")
        
        # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
        if not clean_text1 or not clean_text2:
            return 0.0
        
        # ğŸ¯ ì™„ì „ ì¼ì¹˜ ê²€ì‚¬ (ìµœê³  ìš°ì„ ìˆœìœ„)
        if clean_text1 == clean_text2:
            return 1.0
        
        # ğŸ¯ í•œêµ­ì–´ ê²Œì„ ëª…ë ¹ì–´ ë™ì˜ì–´ ë§¤í•‘
        synonym_groups = {
            # ê³µê²© ê´€ë ¨
            "ê³µê²©": ["ê³µê²©", "ì–´íƒ", "ë•Œë¦¬ê¸°", "ì¹˜ê¸°", "íƒ€ê²©"],
            "ìŠ¤í‚¬": ["ìŠ¤í‚¬", "ê¸°ìˆ ", "ëŠ¥ë ¥", "íŠ¹ìˆ˜ê³µê²©"],
            "ê¶ê·¹ê¸°": ["ê¶ê·¹ê¸°", "ê¶ê·¹", "ìš¸íŠ¸", "í•„ì‚´ê¸°", "ëŒ€ê¸°ìˆ "],
            
            # ì´ë™ ê´€ë ¨  
            "ë‹¬ë¦¬ê¸°": ["ë‹¬ë¦¬ê¸°", "ë›°ê¸°", "ëŸ°", "ìŠ¤í”„ë¦°íŠ¸"],
            "ì í”„": ["ì í”„", "ë›°ê¸°", "ë›°ì–´ì˜¤ë¥´ê¸°", "ì í”„í•˜ê¸°"],
            
            # ì•„ì´í…œ ê´€ë ¨
            "ì•„ì´í…œ": ["ì•„ì´í…œ", "í…œ", "ë¬¼ê±´", "ë„êµ¬"],
            "í¬ì…˜": ["í¬ì…˜", "ë¬¼ì•½", "ííŒ©", "íšŒë³µì•½"],
            "ë¬´ê¸°": ["ë¬´ê¸°", "ì›¨í°", "ê²€", "ì´", "ì¹¼"],
            
            # ì•¡ì…˜ ê´€ë ¨
            "ë°©ì–´": ["ë°©ì–´", "ë§‰ê¸°", "ê°€ë“œ", "ë¸”ë¡"],
            "íë§": ["íë§", "íšŒë³µ", "ì¹˜ë£Œ", "í"],
            "ì½¤ë³´": ["ì½¤ë³´", "ì—°ê³„", "ì—°ì†ê¸°"],
            "ì—°ì‚¬": ["ì—°ì‚¬", "ë¹ ë¥¸ê³µê²©", "ìë™ê³µê²©", "ì†ì‚¬"],
            
            # ì œì–´ ê´€ë ¨
            "ì‹œì‘": ["ì‹œì‘", "ìŠ¤íƒ€íŠ¸", "ê°œì‹œ", "ì‹¤í–‰"],
            "ì¤‘ì§€": ["ì¤‘ì§€", "ì •ì§€", "ìŠ¤í†±", "ë©ˆì¶¤"],
            "ì¼ì‹œì •ì§€": ["ì¼ì‹œì •ì§€", "ë©ˆì¶¤", "í¬ì¦ˆ"],
            "ì¬ì‹œì‘": ["ì¬ì‹œì‘", "ë¦¬ìŠ¤íƒ€íŠ¸", "ë‹¤ì‹œì‹œì‘"],
            
            # ìˆ«ì ê´€ë ¨
            "1": ["1", "í•˜ë‚˜", "ì¼", "ì›"],
            "2": ["2", "ë‘˜", "ì´", "íˆ¬"],
            "3": ["3", "ì…‹", "ì‚¼", "ì“°ë¦¬"],
            "4": ["4", "ë„·", "ì‚¬", "í¬"],
            "5": ["5", "ë‹¤ì„¯", "ì˜¤", "íŒŒì´ë¸Œ"]
        }
        
        # ğŸ”„ ë™ì˜ì–´ í™•ì¥ ê²€ì‚¬
        def get_canonical_word(word):
            """ë‹¨ì–´ë¥¼ í‘œì¤€í˜•ìœ¼ë¡œ ë³€í™˜"""
            for canonical, synonyms in synonym_groups.items():
                if word in synonyms:
                    return canonical
            return word
        
        canonical_text1 = get_canonical_word(clean_text1)
        canonical_text2 = get_canonical_word(clean_text2)
        
        # í‘œì¤€í˜•ìœ¼ë¡œ ì™„ì „ ì¼ì¹˜ ê²€ì‚¬
        if canonical_text1 == canonical_text2:
            return 0.95  # ë™ì˜ì–´ ì¼ì¹˜
        
        # ğŸ¯ ë¶€ë¶„ ì¼ì¹˜ ê²€ì‚¬ (í¬í•¨ ê´€ê³„)
        if clean_text1 in clean_text2 or clean_text2 in clean_text1:
            longer_text = max(clean_text1, clean_text2, key=len)
            shorter_text = min(clean_text1, clean_text2, key=len)
            # ë¶€ë¶„ ì¼ì¹˜ ì ìˆ˜ = ì§§ì€ í…ìŠ¤íŠ¸ ê¸¸ì´ / ê¸´ í…ìŠ¤íŠ¸ ê¸¸ì´
            partial_score = len(shorter_text) / len(longer_text)
            return min(0.9, 0.7 + partial_score * 0.2)  # ìµœëŒ€ 0.9ì 
        
        # ğŸ¯ ìˆ«ì + í…ìŠ¤íŠ¸ ì¡°í•© ì²˜ë¦¬ (ì˜ˆ: "ìŠ¤í‚¬1", "ìŠ¤í‚¬ 1")
        import re
        
        # ìˆ«ì íŒ¨í„´ ì¶”ì¶œ
        def extract_base_and_number(text):
            match = re.match(r'([^\d]+)(\d+)', text)
            if match:
                return match.group(1).strip(), match.group(2)
            return text, None
        
        base1, num1 = extract_base_and_number(clean_text1)
        base2, num2 = extract_base_and_number(clean_text2)
        
        # ê¸°ë³¸ ë‹¨ì–´ê°€ ê°™ê³  ìˆ«ìë„ ê°™ì€ ê²½ìš°
        if base1 == base2 and num1 == num2 and num1 is not None:
            return 0.95
        
        # ê¸°ë³¸ ë‹¨ì–´ë§Œ ê°™ì€ ê²½ìš° (ìˆ«ì ë‹¤ë¦„)
        if base1 == base2 and num1 is not None and num2 is not None:
            return 0.75
        
        # ğŸ¯ ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ (SequenceMatcher)
        base_similarity = SequenceMatcher(None, clean_text1, clean_text2).ratio()
        
        # ğŸ¯ ììŒ/ëª¨ìŒ ë¶„ë¦¬ ìœ ì‚¬ë„ (í•œêµ­ì–´ íŠ¹í™”)
        def get_consonants_vowels(text):
            """í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ììŒê³¼ ëª¨ìŒ ì¶”ì¶œ"""
            consonants = ""
            vowels = ""
            
            for char in text:
                if 'ê°€' <= char <= 'í£':  # í•œê¸€ì¸ ê²½ìš°
                    # ìœ ë‹ˆì½”ë“œ ë¶„í•´ (ì´ˆì„±, ì¤‘ì„±, ì¢…ì„±)
                    code = ord(char) - ord('ê°€')
                    cho = code // (21 * 28)  # ì´ˆì„±
                    jung = (code % (21 * 28)) // 28  # ì¤‘ì„±
                    jong = code % 28  # ì¢…ì„±
                    
                    # ì´ˆì„± (ììŒ)
                    cho_list = ['ã„±', 'ã„²', 'ã„´', 'ã„·', 'ã„¸', 'ã„¹', 'ã…', 'ã…‚', 'ã…ƒ', 'ã……', 'ã…†', 'ã…‡', 'ã…ˆ', 'ã…‰', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
                    consonants += cho_list[cho]
                    
                    # ì¤‘ì„± (ëª¨ìŒ)
                    jung_list = ['ã…', 'ã…', 'ã…‘', 'ã…’', 'ã…“', 'ã…”', 'ã…•', 'ã…–', 'ã…—', 'ã…˜', 'ã…™', 'ã…š', 'ã…›', 'ã…œ', 'ã…', 'ã…', 'ã…Ÿ', 'ã… ', 'ã…¡', 'ã…¢', 'ã…£']
                    vowels += jung_list[jung]
                    
                    # ì¢…ì„± (ììŒ, ìˆëŠ” ê²½ìš°)
                    if jong > 0:
                        jong_list = ['', 'ã„±', 'ã„²', 'ã„³', 'ã„´', 'ã„µ', 'ã„¶', 'ã„·', 'ã„¹', 'ã„º', 'ã„»', 'ã„¼', 'ã„½', 'ã„¾', 'ã„¿', 'ã…€', 'ã…', 'ã…‚', 'ã…„', 'ã……', 'ã…†', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
                        consonants += jong_list[jong]
                else:
                    # í•œê¸€ì´ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ì¶”ê°€
                    consonants += char
                    vowels += char
            
            return consonants, vowels
        
        try:
            cons1, vowels1 = get_consonants_vowels(clean_text1)
            cons2, vowels2 = get_consonants_vowels(clean_text2)
            
            # ììŒ ìœ ì‚¬ë„ì™€ ëª¨ìŒ ìœ ì‚¬ë„ ê³„ì‚°
            consonant_similarity = SequenceMatcher(None, cons1, cons2).ratio()
            vowel_similarity = SequenceMatcher(None, vowels1, vowels2).ratio()
            
            # í•œêµ­ì–´ íŠ¹í™” ìœ ì‚¬ë„ (ììŒ ê°€ì¤‘ì¹˜ ë†’ì„)
            korean_similarity = consonant_similarity * 0.7 + vowel_similarity * 0.3
            
        except Exception:
            # í•œêµ­ì–´ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìœ ì‚¬ë„ë§Œ ì‚¬ìš©
            korean_similarity = base_similarity
        
        # ğŸ¯ ìµœì¢… ìœ ì‚¬ë„ ê³„ì‚° (ì—¬ëŸ¬ ë°©ë²•ì˜ ê°€ì¤‘ í‰ê· )
        final_similarity = (
            base_similarity * 0.4 +      # ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„
            korean_similarity * 0.4 +    # í•œêµ­ì–´ íŠ¹í™” ìœ ì‚¬ë„
            (1.0 if len(clean_text1) == len(clean_text2) else 0.8) * 0.2  # ê¸¸ì´ ìœ ì‚¬ë„
        )
        
        # ğŸ¯ ê²Œì„ ëª…ë ¹ì–´ íŠ¹ë³„ ë³´ì •
        if any(word in clean_text1 for word in ["ìŠ¤í‚¬", "ê³µê²©", "ì í”„", "ë‹¬ë¦¬ê¸°"]) and \
           any(word in clean_text2 for word in ["ìŠ¤í‚¬", "ê³µê²©", "ì í”„", "ë‹¬ë¦¬ê¸°"]):
            final_similarity += 0.1  # ê²Œì„ ëª…ë ¹ì–´ ë³´ë„ˆìŠ¤
        
        # 0.0 ~ 1.0 ë²”ìœ„ë¡œ ì œí•œ
        return max(0.0, min(1.0, final_similarity))
    
    def find_matching_macros(self, recognized_text: str) -> List[Dict]:
        """
        ì¸ì‹ëœ í…ìŠ¤íŠ¸ì™€ ë§¤í¬ë¡œ ëª…ë ¹ì–´ ë§¤ì¹­
        ğŸ” ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´ í¬í•¨
        
        Args:
            recognized_text (str): ìŒì„± ì¸ì‹ëœ í…ìŠ¤íŠ¸
            
        Returns:
            List[Dict]: ë§¤ì¹­ëœ ë§¤í¬ë¡œ ëª©ë¡ (ìœ ì‚¬ë„ ìˆœ ì •ë ¬)
        """
        if not recognized_text or not recognized_text.strip():
            self.logger.warning("ğŸ” ë§¤í¬ë¡œ ë§¤ì¹­ ì‹¤íŒ¨: ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return []
        
        try:
            # ë§¤í¬ë¡œ ìºì‹œ ì—…ë°ì´íŠ¸
            self._update_macro_cache()
            
            if not self._macro_cache:
                self.logger.warning("ğŸ” ë§¤í¬ë¡œ ë§¤ì¹­ ì‹¤íŒ¨: ë“±ë¡ëœ ë§¤í¬ë¡œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            matches = []
            recognized_text = recognized_text.strip()
            
            self.logger.info(f"ğŸ¯ ë§¤í¬ë¡œ ë§¤ì¹­ ì‹œì‘")
            self.logger.info(f"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{recognized_text}'")
            self.logger.info(f"ğŸ“Š ë“±ë¡ëœ ë§¤í¬ë¡œ ìˆ˜: {len(self._macro_cache)}")
            self.logger.info(f"ğŸ¯ ë§¤ì¹­ ì„ê³„ê°’: {config.MATCHING_THRESHOLD:.2f}")
            
            # ê° ë§¤í¬ë¡œì™€ ìœ ì‚¬ë„ ê³„ì‚°
            all_similarities = []  # ëª¨ë“  ìœ ì‚¬ë„ ì €ì¥ (ë””ë²„ê¹…ìš©)
            
            for i, macro in enumerate(self._macro_cache):
                if not macro.get('voice_command'):
                    continue
                
                voice_command = macro['voice_command']
                similarity = self._calculate_similarity(recognized_text, voice_command)
                
                # ëª¨ë“  ìœ ì‚¬ë„ ê¸°ë¡ (ë””ë²„ê¹…ìš©)
                all_similarities.append({
                    'macro_name': macro['name'],
                    'voice_command': voice_command,
                    'similarity': similarity,
                    'above_threshold': similarity >= config.MATCHING_THRESHOLD
                })
                
                # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ ê²°ê³¼ì— ì¶”ê°€
                if similarity >= config.MATCHING_THRESHOLD:
                    match_result = {
                        'macro_id': macro['id'],
                        'macro_name': macro['name'],
                        'voice_command': voice_command,
                        'action_type': macro['action_type'],
                        'key_sequence': macro['key_sequence'],
                        'similarity': similarity,
                        'confidence': similarity * 100,  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                        'settings': macro.get('settings', {})
                    }
                    matches.append(match_result)
            
            # ğŸ” ìƒì„¸ ë””ë²„ê¹… ì •ë³´ ë¡œê¹…
            self.logger.info(f"ğŸ“ˆ ë§¤í¬ë¡œ ë§¤ì¹­ ë¶„ì„ ê²°ê³¼:")
            
            # ìƒìœ„ 5ê°œ ìœ ì‚¬ë„ ê²°ê³¼ í‘œì‹œ (ì„ê³„ê°’ ë¬´ê´€)
            top_similarities = sorted(all_similarities, key=lambda x: x['similarity'], reverse=True)[:5]
            for j, sim_info in enumerate(top_similarities, 1):
                status = "âœ… ë§¤ì¹­" if sim_info['above_threshold'] else "âŒ ì„ê³„ê°’ ë¯¸ë‹¬"
                self.logger.info(f"   {j}. '{sim_info['voice_command']}' ({sim_info['macro_name']}) - {sim_info['similarity']:.3f} {status}")
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
            matches.sort(key=lambda x: x['similarity'], reverse=True)
            
            # ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜ ì œí•œ
            matches = matches[:config.MAX_MATCH_RESULTS]
            
            # ğŸ¯ ìµœì¢… ë§¤ì¹­ ê²°ê³¼ ë¡œê¹…
            if matches:
                self.logger.info(f"âœ… ë§¤í¬ë¡œ ë§¤ì¹­ ì„±ê³µ: '{recognized_text}' -> {len(matches)}ê°œ ë§¤ì¹­")
                self.logger.info(f"ğŸ† ìµœê³  ë§¤ì¹­ ê²°ê³¼:")
                for k, match in enumerate(matches[:3], 1):  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    self.logger.info(f"   {k}. '{match['voice_command']}' ({match['macro_name']}) - {match['confidence']:.1f}%")
                
                # ë§¤ì¹­ í’ˆì§ˆ í‰ê°€
                best_similarity = matches[0]['similarity']
                if best_similarity >= 0.9:
                    quality = "ğŸŒŸ ìš°ìˆ˜"
                elif best_similarity >= 0.8:
                    quality = "ğŸ‘ ì–‘í˜¸"
                elif best_similarity >= 0.7:
                    quality = "âš ï¸  ë³´í†µ"
                else:
                    quality = "âš ï¸  ë‚®ìŒ"
                
                self.logger.info(f"ğŸ“Š ë§¤ì¹­ í’ˆì§ˆ: {quality} (ìµœê³  ìœ ì‚¬ë„: {best_similarity:.3f})")
                
            else:
                self.logger.warning(f"âŒ ë§¤í¬ë¡œ ë§¤ì¹­ ì‹¤íŒ¨: '{recognized_text}'")
                self.logger.warning(f"ğŸ” ê°€ëŠ¥í•œ ì›ì¸:")
                
                if not all_similarities:
                    self.logger.warning(f"   - ìŒì„± ëª…ë ¹ì–´ê°€ ì„¤ì •ëœ ë§¤í¬ë¡œê°€ ì—†ìŒ")
                else:
                    max_similarity = max(s['similarity'] for s in all_similarities)
                    closest_match = next(s for s in all_similarities if s['similarity'] == max_similarity)
                    
                    self.logger.warning(f"   - ê°€ì¥ ìœ ì‚¬í•œ ëª…ë ¹ì–´: '{closest_match['voice_command']}' (ìœ ì‚¬ë„: {max_similarity:.3f})")
                    self.logger.warning(f"   - ì„ê³„ê°’ ë¶€ì¡±: {max_similarity:.3f} < {config.MATCHING_THRESHOLD:.3f}")
                    
                    # ê°œì„  ì œì•ˆ
                    if max_similarity > 0.5:
                        self.logger.warning(f"ğŸ’¡ ê°œì„  ì œì•ˆ: ì„ê³„ê°’ì„ {max_similarity:.2f}ë¡œ ë‚®ì¶”ê±°ë‚˜ ìŒì„± ëª…ë ¹ì–´ë¥¼ '{recognized_text}'ë¡œ ìˆ˜ì •")
            
            return matches
            
        except Exception as e:
            self.logger.error(f"âŒ ë§¤í¬ë¡œ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def process_voice_command(self, audio_input) -> Dict:
        """
        ìŒì„± ëª…ë ¹ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        ì˜¤ë””ì˜¤ -> í…ìŠ¤íŠ¸ ë³€í™˜ -> ë§¤í¬ë¡œ ë§¤ì¹­
        
        Args:
            audio_input: ì˜¤ë””ì˜¤ ë°ì´í„° (np.ndarray) ë˜ëŠ” íŒŒì¼ ê²½ë¡œ (str)
            
        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = datetime.now()
        
        result = {
            'success': False,
            'recognized_text': '',
            'matched_macros': [],
            'processing_time': 0,
            'error': None,
            'transcription_result': {}
        }
        
        try:
            # 1ë‹¨ê³„: ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
            self.logger.info("ìŒì„± ì¸ì‹ ì‹œì‘...")
            transcription_result = self.transcribe_audio(audio_input)
            result['transcription_result'] = transcription_result
            
            if not transcription_result.get('success'):
                result['error'] = transcription_result.get('error', 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
                return result
            
            recognized_text = transcription_result.get('text', '')
            if not recognized_text.strip():
                result['error'] = 'ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'
                return result
            
            result['recognized_text'] = recognized_text
            
            # 2ë‹¨ê³„: ë§¤í¬ë¡œ ë§¤ì¹­
            self.logger.info("ë§¤í¬ë¡œ ë§¤ì¹­ ì‹œì‘...")
            matched_macros = self.find_matching_macros(recognized_text)
            
            result['matched_macros'] = matched_macros
            result['success'] = True
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            result['processing_time'] = processing_time
            
            self.logger.info(f"ìŒì„± ëª…ë ¹ ì²˜ë¦¬ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
            
        except Exception as e:
            result['error'] = f'ìŒì„± ëª…ë ¹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            self.logger.error(result['error'])
        
        return result
    
    def get_service_status(self) -> Dict:
        """
        Whisper ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict: ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´
        """
        return {
            'client_initialized': self.client is not None,
            'api_key_configured': bool(config.OPENAI_API_KEY),
            'model': self.model,
            'language': self.language,
            'sample_rate': self.sample_rate,
            'temp_dir': config.TEMP_AUDIO_DIR,
            'temp_dir_exists': os.path.exists(config.TEMP_AUDIO_DIR),
            'macro_cache_size': len(self._macro_cache),
            'cache_last_updated': self._cache_last_updated.isoformat() if self._cache_last_updated else None
        }


# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
whisper_service = WhisperService() 