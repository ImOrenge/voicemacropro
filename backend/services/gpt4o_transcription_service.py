"""
GPT-4o ì‹¤ì‹œê°„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤
VoiceMacro Proë¥¼ ìœ„í•œ ê²Œì„ ëª…ë ¹ì–´ ìµœì í™” ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ
"""

import asyncio
import websockets
import json
import base64
import logging
from typing import Optional, Callable, Dict, Any
from datetime import datetime

class GPT4oTranscriptionService:
    """ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ì„ ìœ„í•œ GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: str):
        """
        GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            api_key (str): OpenAI API í‚¤
        """
        self.api_key = api_key
        self.websocket: Optional[websockets.WebSocketServerProtocol] = None
        self.session_id: Optional[str] = None
        self.is_connected = False
        self.transcription_callback: Optional[Callable] = None
        self.logger = logging.getLogger(__name__)
        
        # ê²Œì„ ëª…ë ¹ì–´ ìµœì í™”ë¥¼ ìœ„í•œ ì„¸ì…˜ ì„¤ì •
        self.session_config = {
            "type": "transcription_session.update",
            "input_audio_format": "pcm16",  # 24kHz PCM16 ì˜¤ë””ì˜¤
            "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "prompt": self._get_gaming_optimized_prompt(),
                "language": "ko"  # í•œêµ­ì–´ ê²Œì„ ëª…ë ¹ì–´
            },
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500
            },
            "input_audio_noise_reduction": {
                "type": "near_field"  # í—¤ë“œì…‹ ë§ˆì´í¬ ìµœì í™”
            },
            "include": ["item.input_audio_transcription.logprobs"]
        }
    
    def _get_gaming_optimized_prompt(self) -> str:
        """ê²Œì„ ëª…ë ¹ì–´ ì¸ì‹ ìµœì í™”ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸"""
        return """
        ê²Œì„ í”Œë ˆì´ì–´ì˜ ìŒì„± ëª…ë ¹ì–´ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ì„¸ìš”.
        ì£¼ìš” ëª…ë ¹ì–´ íŒ¨í„´:
        - ê³µê²©: ê³µê²©, ì–´íƒ, ë•Œë ¤, ì¹˜ê¸°, ê³µê²©í•´
        - ìŠ¤í‚¬: ìŠ¤í‚¬, ê¸°ìˆ , ë§ˆë²•, ê¶ê·¹ê¸°, ìŠ¤í˜ì…œ
        - ì´ë™: ì•ìœ¼ë¡œ, ë’¤ë¡œ, ì¢Œì¸¡, ìš°ì¸¡, ì í”„, ë‹¬ë ¤
        - ì•„ì´í…œ: í¬ì…˜, íšŒë³µ, ì•„ì´í…œ, ì‚¬ìš©, ë¨¹ê¸°
        - ë°©ì–´: ë°©ì–´, ë§‰ê¸°, í”¼í•˜ê¸°, íšŒí”¼
        ì§§ê³  ëª…í™•í•œ ê²Œì„ ëª…ë ¹ì–´ë¥¼ ìš°ì„  ì¸ì‹í•˜ì„¸ìš”.
        """
    
    async def connect(self) -> bool:
        """OpenAI Realtime APIì— WebSocket ì—°ê²°"""
        try:
            uri = "wss://api.openai.com/v1/realtime"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "OpenAI-Beta": "realtime=v1"
            }
            
            self.websocket = await websockets.connect(uri, extra_headers=headers)
            await self._initialize_session()
            self.is_connected = True
            self.logger.info("GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ")
            return True
            
        except Exception as e:
            self.logger.error(f"GPT-4o ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    async def _initialize_session(self):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„¸ì…˜ ì´ˆê¸°í™”"""
        await self.websocket.send(json.dumps(self.session_config))
        
        # ì„¸ì…˜ ìƒì„± í™•ì¸ ëŒ€ê¸°
        response = await self.websocket.recv()
        session_data = json.loads(response)
        
        if session_data.get("type") == "transcription_session.created":
            self.session_id = session_data.get("id")
            self.logger.info(f"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„¸ì…˜ ìƒì„±ë¨: {self.session_id}")
    
    async def send_audio_chunk(self, audio_data: bytes):
        """
        ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
        
        Args:
            audio_data (bytes): PCM16 í˜•ì‹ì˜ ì˜¤ë””ì˜¤ ë°ì´í„° (24kHz)
        """
        if not self.is_connected or not self.websocket:
            raise ConnectionError("íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ì— ì—°ê²°ë˜ì§€ ì•ŠìŒ")
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        message = {
            "type": "input_audio_buffer.append",
            "audio": audio_base64
        }
        
        await self.websocket.send(json.dumps(message))
    
    async def commit_audio_buffer(self):
        """ìˆ˜ë™ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë²„í¼ ì»¤ë°‹ (VAD ë¹„í™œì„±í™” ì‹œ ì‚¬ìš©)"""
        if not self.is_connected or not self.websocket:
            return
            
        message = {"type": "input_audio_buffer.commit"}
        await self.websocket.send(json.dumps(message))
    
    async def listen_for_transcriptions(self):
        """íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì‹¤ì‹œê°„ ìˆ˜ì‹ """
        try:
            async for message in self.websocket:
                data = json.loads(message)
                await self._handle_transcription_event(data)
                
        except websockets.exceptions.ConnectionClosed:
            self.logger.warning("íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì—°ê²°ì´ ì¢…ë£Œë¨")
            self.is_connected = False
        except Exception as e:
            self.logger.error(f"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
    
    async def _handle_transcription_event(self, event: Dict[str, Any]):
        """
        íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì´ë²¤íŠ¸ ì²˜ë¦¬
        
        Args:
            event (Dict[str, Any]): OpenAI Realtime API ì´ë²¤íŠ¸ ë°ì´í„°
        """
        event_type = event.get("type")
        
        if event_type == "conversation.item.input_audio_transcription.delta":
            # ì‹¤ì‹œê°„ ë¶€ë¶„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜
            delta_text = event.get("delta", "")
            item_id = event.get("item_id")
            
            if self.transcription_callback:
                await self.transcription_callback({
                    "type": "partial",
                    "text": delta_text,
                    "item_id": item_id,
                    "timestamp": datetime.now().isoformat()
                })
        
        elif event_type == "conversation.item.input_audio_transcription.completed":
            # ì™„ë£Œëœ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼
            transcript = event.get("transcript", "")
            item_id = event.get("item_id")
            confidence_score = self._calculate_confidence(event.get("logprobs", []))
            
            if self.transcription_callback:
                await self.transcription_callback({
                    "type": "final",
                    "text": transcript,
                    "item_id": item_id,
                    "confidence": confidence_score,
                    "timestamp": datetime.now().isoformat()
                })
        
        elif event_type == "input_audio_buffer.committed":
            # ì˜¤ë””ì˜¤ ë²„í¼ ì»¤ë°‹ ì™„ë£Œ
            self.logger.debug(f"ì˜¤ë””ì˜¤ ë²„í¼ ì»¤ë°‹ë¨: {event.get('item_id')}")
        
        elif event_type == "error":
            # API ì˜¤ë¥˜ ì²˜ë¦¬
            error_msg = event.get("error", {}).get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            self.logger.error(f"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ API ì˜¤ë¥˜: {error_msg}")
    
    def _calculate_confidence(self, logprobs: list) -> float:
        """
        ë¡œê·¸ í™•ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        
        Args:
            logprobs (list): í† í°ë³„ ë¡œê·¸ í™•ë¥  ë¦¬ìŠ¤íŠ¸
            
        Returns:
            float: 0.0 ~ 1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„ ì ìˆ˜
        """
        if not logprobs:
            return 0.0
        
        # ë¡œê·¸ í™•ë¥ ì„ í™•ë¥ ë¡œ ë³€í™˜í•˜ê³  í‰ê·  ê³„ì‚°
        probs = [min(1.0, max(0.0, 2 ** logprob)) for logprob in logprobs if logprob is not None]
        return sum(probs) / len(probs) if probs else 0.0
    
    def set_transcription_callback(self, callback: Callable):
        """
        íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì½œë°± í•¨ìˆ˜ ì„¤ì •
        
        Args:
            callback (Callable): íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•  ë¹„ë™ê¸° í•¨ìˆ˜
        """
        self.transcription_callback = callback
    
    async def disconnect(self):
        """WebSocket ì—°ê²° ì¢…ë£Œ"""
        if self.websocket and not self.websocket.closed:
            await self.websocket.close()
        self.is_connected = False
        self.session_id = None
        self.logger.info("GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ ì—°ê²° í•´ì œ")


# í…ŒìŠ¤íŠ¸ìš© ì˜ˆì œ í•¨ìˆ˜ë“¤
async def example_transcription_handler(transcription_data: Dict[str, Any]):
    """
    íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì²˜ë¦¬ ì˜ˆì œ í•¨ìˆ˜
    
    Args:
        transcription_data (Dict[str, Any]): íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ë°ì´í„°
    """
    if transcription_data["type"] == "partial":
        print(f"ğŸ™ï¸ ë¶€ë¶„ ì¸ì‹: {transcription_data['text']}")
    elif transcription_data["type"] == "final":
        print(f"âœ… ìµœì¢… ì¸ì‹: {transcription_data['text']} (ì‹ ë¢°ë„: {transcription_data['confidence']:.2f})")


async def test_gpt4o_service(api_key: str):
    """
    GPT-4o íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    
    Args:
        api_key (str): OpenAI API í‚¤
    """
    service = GPT4oTranscriptionService(api_key)
    service.set_transcription_callback(example_transcription_handler)
    
    if await service.connect():
        print("GPT-4o ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ!")
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ìˆ˜ì‹ 
        listen_task = asyncio.create_task(service.listen_for_transcriptions())
        
        # ì—¬ê¸°ì„œ ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì „ì†¡í•  ìˆ˜ ìˆìŒ
        # await service.send_audio_chunk(audio_data)
        
        try:
            await listen_task
        except KeyboardInterrupt:
            print("ì„œë¹„ìŠ¤ ì¢…ë£Œ ì¤‘...")
            await service.disconnect()
    else:
        print("GPT-4o ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨!")


if __name__ == "__main__":
    import os
    api_key = os.getenv('OPENAI_API_KEY')
    if api_key:
        asyncio.run(test_gpt4o_service(api_key))
    else:
        print("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.") 